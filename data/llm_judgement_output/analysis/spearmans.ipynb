{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92db97cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "Analyzing L_rate\n",
      "========================================\n",
      "Base vs Large LLM Correlations for L_rate:\n",
      "Base_LLM     Large_LLM  Correlation\n",
      "   Gemma   Gemma-large       0.9708\n",
      "   Llama   Llama-large       0.7235\n",
      " Mistral Mistral-large       0.9284\n",
      "    Qwen    Qwen-large       0.9198\n",
      "\n",
      "========================================\n",
      "Analyzing L_nonword\n",
      "========================================\n",
      "Base vs Large LLM Correlations for L_nonword:\n",
      "Base_LLM     Large_LLM  Correlation\n",
      "   Gemma   Gemma-large       0.0578\n",
      "   Llama   Llama-large       0.9120\n",
      " Mistral Mistral-large       0.8599\n",
      "    Qwen    Qwen-large       0.8456\n",
      "\n",
      "========================================\n",
      "Analyzing C_rate\n",
      "========================================\n",
      "Base vs Large LLM Correlations for C_rate:\n",
      "Base_LLM     Large_LLM  Correlation\n",
      "   Gemma   Gemma-large       0.5385\n",
      "   Llama   Llama-large       0.9666\n",
      " Mistral Mistral-large       0.9842\n",
      "    Qwen    Qwen-large       0.9958\n",
      "\n",
      "========================================\n",
      "Analyzing C_outlier\n",
      "========================================\n",
      "Base vs Large LLM Correlations for C_outlier:\n",
      "Base_LLM     Large_LLM  Correlation\n",
      "   Gemma   Gemma-large       0.7897\n",
      "   Llama   Llama-large       0.5127\n",
      " Mistral Mistral-large       0.7991\n",
      "    Qwen    Qwen-large       0.7732\n",
      "\n",
      "========================================\n",
      "Analyzing R_rate\n",
      "========================================\n",
      "Base vs Large LLM Correlations for R_rate:\n",
      "Base_LLM     Large_LLM  Correlation\n",
      "   Gemma   Gemma-large       0.4350\n",
      "   Llama   Llama-large       0.8482\n",
      " Mistral Mistral-large       0.1912\n",
      "    Qwen    Qwen-large       0.9899\n",
      "\n",
      "========================================\n",
      "Analyzing R_duplicate\n",
      "========================================\n",
      "Base vs Large LLM Correlations for R_duplicate:\n",
      "Base_LLM     Large_LLM  Correlation\n",
      "   Gemma   Gemma-large       0.8609\n",
      "   Llama   Llama-large       0.7509\n",
      " Mistral Mistral-large      -0.0325\n",
      "    Qwen    Qwen-large      -0.6227\n",
      "\n",
      "========================================\n",
      "Analyzing D_rate\n",
      "========================================\n",
      "Base vs Large LLM Correlations for D_rate:\n",
      "Base_LLM     Large_LLM  Correlation\n",
      "   Gemma   Gemma-large       0.3674\n",
      "   Llama   Llama-large       0.4794\n",
      " Mistral Mistral-large       0.9170\n",
      "    Qwen    Qwen-large       0.5980\n",
      "\n",
      "========================================\n",
      "Analyzing A_ir-tw\n",
      "========================================\n",
      "Base vs Large LLM Correlations for A_ir-tw:\n",
      "Base_LLM     Large_LLM  Correlation\n",
      "   Gemma   Gemma-large      -0.2043\n",
      "   Llama   Llama-large       0.9980\n",
      " Mistral Mistral-large       0.9993\n",
      "    Qwen    Qwen-large       0.3088\n",
      "\n",
      "========================================\n",
      "Analyzing A_missing-theme\n",
      "========================================\n",
      "Base vs Large LLM Correlations for A_missing-theme:\n",
      "Base_LLM     Large_LLM  Correlation\n",
      "   Gemma   Gemma-large       0.7759\n",
      "   Llama   Llama-large       0.9209\n",
      " Mistral Mistral-large       0.7216\n",
      "    Qwen    Qwen-large       0.8423\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"merge.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Define LLM pairs to compare\n",
    "LLM_PAIRS = [\n",
    "    ('Gemma', 'Gemma-large'),\n",
    "    ('Llama', 'Llama-large'),\n",
    "    ('Mistral', 'Mistral-large'),\n",
    "    ('Qwen', 'Qwen-large')\n",
    "]\n",
    "\n",
    "# -------------------------------\n",
    "# Analysis for all metrics\n",
    "# -------------------------------\n",
    "TARGET_METRICS = [\"L_rate\", \"L_nonword\", \"C_rate\", \"C_outlier\", \n",
    "                 \"R_rate\", \"R_duplicate\", \"D_rate\", \"A_ir-tw\", \n",
    "                 \"A_missing-theme\"]\n",
    "\n",
    "for TARGET_METRIC in TARGET_METRICS:\n",
    "    print(f\"\\n{'='*40}\\nAnalyzing {TARGET_METRIC}\\n{'='*40}\")\n",
    "    \n",
    "    # Filter and clean data\n",
    "    df_metric = df[df[\"LLM-based Metric\"] == TARGET_METRIC].copy()\n",
    "    df_metric = df_metric.drop(columns=[\"LLM-based Metric\"])\n",
    "\n",
    "    # Melt to long format\n",
    "    melted = df_metric.melt(\n",
    "        id_vars=[\"LLM\", \"K\"],\n",
    "        var_name=\"Method_Dataset\",\n",
    "        value_name=\"Score\"\n",
    "    )\n",
    "    melted[\"Score\"] = pd.to_numeric(melted[\"Score\"], errors=\"coerce\")\n",
    "\n",
    "    # Pivot to wide format\n",
    "    pivoted = melted.pivot_table(\n",
    "        index=[\"Method_Dataset\", \"K\"],\n",
    "        columns=\"LLM\",\n",
    "        values=\"Score\",\n",
    "        aggfunc=\"mean\"\n",
    "    ).reset_index()\n",
    "\n",
    "    # Clean columns\n",
    "    pivoted.columns.name = None\n",
    "    llm_columns = [col for col in pivoted.columns \n",
    "                  if col not in [\"Method_Dataset\", \"K\"]]\n",
    "    pivoted_llms = pivoted[llm_columns].dropna()\n",
    "\n",
    "    # Calculate correlation matrix\n",
    "    corr_matrix = pivoted_llms.corr(method=\"pearson\")\n",
    "\n",
    "    # Extract specific base-large pairs\n",
    "    results = []\n",
    "    for base, large in LLM_PAIRS:\n",
    "        if base in corr_matrix.columns and large in corr_matrix.columns:\n",
    "            corr = corr_matrix.loc[base, large]\n",
    "            results.append({\n",
    "                'Base_LLM': base,\n",
    "                'Large_LLM': large,\n",
    "                'Correlation': round(corr, 4)\n",
    "            })\n",
    "\n",
    "    # Create and display results\n",
    "    result_df = pd.DataFrame(results)\n",
    "    if not result_df.empty:\n",
    "        print(f\"Base vs Large LLM Correlations for {TARGET_METRIC}:\")\n",
    "        print(result_df.to_string(index=False))\n",
    "    else:\n",
    "        print(\"No valid LLM pairs found for this metric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "174d5278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[ht]\n",
      "\\caption{Average Performance Across All Datasets (20NG, AGRIS, TWEETS\\\\_NYR) and K Values (50, 100)}\n",
      "\\label{tab:llm\\_averages}\n",
      "\\begin{tabular}{lccccccccc}\n",
      "\\toprule\n",
      "LLM & Gemma & Gemma-large & Llama & Llama-large & Mistral & Mistral-large & Qwen & Qwen-large & automated \\\\\n",
      "\\textbf{Metric} & \\textbf{Gemma} & \\textbf{Gemma-large} & \\textbf{Llama} & \\textbf{Llama-large} & \\textbf{Mistral} & \\textbf{Mistral-large} & \\textbf{Qwen} & \\textbf{Qwen-large} & \\textbf{automated} &  &  &  &  &  &  &  &  &  \\\\\n",
      "\\midrule\n",
      "Lexical Validity Rate (↑) & 2.780000 & 2.770000 & 2.300000 & 2.840000 & 2.800000 & 2.740000 & 2.770000 & 2.860000 & NaN \\\\\n",
      "Non-word Errors (↓) & 0.260000 & 0.210000 & 1.220000 & 1.150000 & 0.170000 & 0.720000 & 1.680000 & 0.540000 & NaN \\\\\n",
      "Coherence Rate (↑) & 2.260000 & 2.330000 & 2.600000 & 2.430000 & 2.560000 & 2.340000 & 2.000000 & 2.020000 & NaN \\\\\n",
      "Outliers (↓) & 1.690000 & 1.710000 & 1.670000 & 2.190000 & 1.010000 & 1.630000 & 2.210000 & 2.900000 & NaN \\\\\n",
      "Repetitiveness Rate (↑) & 1.990000 & 1.890000 & 1.720000 & 1.760000 & 2.040000 & 2.070000 & 2.490000 & 2.540000 & NaN \\\\\n",
      "Duplicates (↓) & 2.400000 & 1.340000 & 2.650000 & 1.310000 & 3.390000 & 1.790000 & 0.650000 & 2.580000 & NaN \\\\\n",
      "Diversity Rate (↑) & 2.080000 & 2.930000 & 2.780000 & 2.910000 & 2.400000 & 2.100000 & 3.000000 & 2.960000 & NaN \\\\\n",
      "Irrelevant Terms (↓) & 4.960000 & 4.400000 & 5.700000 & 6.020000 & 5.330000 & 5.280000 & 6.150000 & 7.850000 & NaN \\\\\n",
      "Missing Themes (↓) & 5.710000 & 6.410000 & 5.270000 & 6.360000 & 3.820000 & 6.820000 & 7.260000 & 7.420000 & NaN \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"merge.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Define datasets and topic models\n",
    "datasets = [\"20NG\", \"AGRIS\", \"TWEETS_NYR\"]\n",
    "topic_models = [\"LDA\", \"ProdLDA\", \"CombineTM\", \"BERTopic\"]\n",
    "\n",
    "# Melt to long format\n",
    "melted = df.melt(\n",
    "    id_vars=[\"LLM-based Metric\", \"LLM\", \"K\"],\n",
    "    var_name=\"Dataset_TopicModel\",\n",
    "    value_name=\"Value\"\n",
    ")\n",
    "\n",
    "# Split Dataset_TopicModel into components\n",
    "melted[[\"TopicModel\", \"Dataset\"]] = melted[\"Dataset_TopicModel\"].str.split(\"-\", n=1, expand=True)\n",
    "\n",
    "# Filter valid datasets and average across all datasets, topic models, and K values\n",
    "average_df = (\n",
    "    melted.groupby([\"LLM-based Metric\", \"LLM\"])\n",
    "    .Value.mean()\n",
    "    .reset_index()\n",
    "    .pivot(index=\"LLM-based Metric\", columns=\"LLM\", values=\"Value\")\n",
    "    .round(2)\n",
    ")\n",
    "\n",
    "# Rename metrics for clarity\n",
    "metric_names = {\n",
    "    \"L_rate\": \"Lexical Validity Rate (↑)\",\n",
    "    \"L_nonword\": \"Non-word Errors (↓)\",\n",
    "    \"C_rate\": \"Coherence Rate (↑)\",\n",
    "    \"C_outlier\": \"Outliers (↓)\",\n",
    "    \"R_rate\": \"Repetitiveness Rate (↑)\",\n",
    "    \"R_duplicate\": \"Duplicates (↓)\",\n",
    "    \"D_rate\": \"Diversity Rate (↑)\",\n",
    "    \"A_ir-tw\": \"Irrelevant Terms (↓)\",\n",
    "    \"A_missing-theme\": \"Missing Themes (↓)\",\n",
    "}\n",
    "average_df.rename(index=metric_names, inplace=True)\n",
    "\n",
    "# Reorder rows logically\n",
    "row_order = [\n",
    "    \"Lexical Validity Rate (↑)\", \"Non-word Errors (↓)\",\n",
    "    \"Coherence Rate (↑)\", \"Outliers (↓)\",\n",
    "    \"Repetitiveness Rate (↑)\", \"Duplicates (↓)\",\n",
    "    \"Diversity Rate (↑)\",\n",
    "    \"Irrelevant Terms (↓)\", \"Missing Themes (↓)\"\n",
    "]\n",
    "average_df = average_df.loc[row_order]\n",
    "\n",
    "latex_table = average_df.to_latex(\n",
    "    caption=\"Average Performance Across All Datasets (20NG, AGRIS, TWEETS\\\\_NYR) and K Values (50, 100)\",\n",
    "    label=\"tab:llm_averages\",\n",
    "    position=\"ht\",\n",
    "    column_format=\"l\" + \"c\" * len(average_df.columns),\n",
    "    escape=False\n",
    ")\n",
    "\n",
    "# Add LaTeX formatting\n",
    "latex_table = latex_table.replace(\n",
    "    \"LLM-based Metric\", \n",
    "    \"\\\\textbf{Metric} & \\\\textbf{\" + \"} & \\\\textbf{\".join(average_df.columns) + \"}\"\n",
    ").replace(\"_\", \"\\\\_\")\n",
    "\n",
    "print(latex_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Agri-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
